# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1scfA9fNv0qU7ulp2v-PQl7oD7RSbc-gG
"""

#분석할 텍스트 데이터 불러오기 
import pandas as pd
df = pd.read_csv('/content/StoryImageText.csv', encoding='utf-8')
df[0:57]

#제품 페이지 데이터 가져오기

title = ["FirstPic", "ProductFeature", "Eco-Storytelling"]
main_txt2 = []
result = []

#\n 제거, 리스트 합치기 

for main in title:
  main_txt = df[main].to_list()  
  for v in main_txt:
   if type(v) != str:
     main_txt2.append(str(v).replace('\n', ' '))
   elif type(v) == str:
     main_txt2.append(v.replace('\n', ' '))
  
  result.append(" ".join(main_txt2))
  main_txt2.clear()

print(result)
len(result)

#필요한 패키지 설치 
! apt-get install g++ openjdk-8-jdk python3-dev python3-pip curl
! python3 -m pip install --upgrade pip
! python3 -m pip install konlpy

print(result[0])

from konlpy.tag import Okt
import numpy as np
okt = Okt()

#동사/부사/형용사 추출 
clean_verbs = []
clean_nouns = []
clean_adjs = []
clean_all = []
clean_result = []

for j, tag in enumerate(result):
  for word in okt.pos(tag, stem=True):      #어근
    if word[1] in ['Adjective']:
      clean_adjs.append(word[0])
      clean_all.append(word[0]) 
    elif word[1] in ['Verb']:
      clean_verbs.append(word[0])
      clean_all.append(word[0]) 
    elif word[1] in ['Noun']:
      clean_nouns.append(word[0])
      clean_all.append(word[0]) 
  clean_result.append(" ".join(clean_all))
  clean_all.clear()

print(clean_result)
len(clean_result[0])

print(clean_nouns)
len(clean_nouns)

from collections import Counter
Counter(clean_adjs).most_common()

top_nouns = {'피부': 70, '차단': 35, '자외선': 33, '무기': 33, '성분': 19, '발림': 16, '수분':16, '톤업':9, '밀림': 4, '흡수': 12}

from sklearn.feature_extraction.text import TfidfVectorizer 

sunscreen_tfidv = TfidfVectorizer().fit(top_nouns)
sunscreen_tfidv.transform(clean_result).toarray()

pd.DataFrame(sunscreen_tfidv.transform(clean_result).toarray())

top_nouns2 = {'환경': 13, '산호초': 8, '산호': 5,  '해양': 7, '위해': 6, '비건': 9, '민감': 6, '메이크업': 6, '효과': 6, '시림': 5, '궁합': 5,  '고민': 4}

from sklearn.feature_extraction.text import TfidfVectorizer 

sunscreen_tfidv = TfidfVectorizer().fit(top_nouns2)
sunscreen_tfidv.transform(clean_result).toarray()

pd.DataFrame(sunscreen_tfidv.transform(clean_result).toarray())

top_adj = {'촉촉하다': 14, '좋다': 11, '가볍다': 9, '순하다': 8, '안전하다': 8, '자연스럽다': 6, '민감하다': 5, '건강하다': 3, '강력하다': 3, '건조하다': 3, '보송하다': 3, '산뜻하다': 2, '확실하다': 2}

from sklearn.feature_extraction.text import TfidfVectorizer 

sunscreen_tfidv = TfidfVectorizer().fit(top_adj)
sunscreen_tfidv.transform(clean_result).toarray()

pd.DataFrame(sunscreen_tfidv.transform(clean_result).toarray())